# Neuromodulatory-Control-Networks
Large Language Models (LLMs) based on the Transformer architecture have achieved remarkable success, yet their core processing mechanisms remain largely static after training. While powerful, this static nature limits their ability to dynamically adapt their processing strategy based on nuanced contextual cues, task demands, or desired operational modes (e.g., shifting between exploration and exploitation). We propose Neuromodulatory Control Networks (NCNs), a novel architectural modification inspired by the neuromodulatory systems in the vertebrate brain (e.g., those utilizing dopamine, acetylcholine, norepinephrine). NCNs are small, parallel networks that receive contextual input, summarizing the global state, task information, or external control signals, and compute dynamic "modulatory signals". These signals are distributed as layer-specific control vectors to the main LLM to influence its computational properties during a forward pass, analogous to how neuromodulators alter neuronal gain, plasticity, and network states across different cortical depths. Instead of merely routing information, NCNs aim to change *how* information is processed throughout the base model by modulating key components like attention mechanisms (e.g., via precision scaling), layer gains, and activation functions. Crucially, the architecture allows the model to *implicitly learn* to self-regulate these parameters via backpropagation, effectively becoming its own "tuning expert." We further introduce formal stability mechanisms, including homeostatic regularization, to prevent control manifold collapse. This paper introduces the NCN architecture, details its components and implicit learning mechanism, discusses its conceptual advantages and potential failure modes (such as contextual stereotyping), and provides an open-source PyTorch implementation to facilitate community exploration and future empirical validation. 

# What does it do? How does it work?
The Neuromodulatory Control Network architecture operates by running a compact neural network in parallel with the main LLM. When the system processes an input sequence, the NCN generates a latent representation, consisting of a sequence of 768-dimensional vectors, that captures the specific "texture" of the input. During training, the network uses end-to-end gradient modulation to dynamically adjust the attention temperature, layer gain, and feed-forward gating, implicitly learning which parameter states minimize loss for different contexts. For example, if a user asks a standard math question, the NCN detects the context and lowers the temperature to encourage fact recall, whereas asking the model to write a poem results in the NCN increasing temperature to foster creativity. We recently updated the architecture to make these representations "phasic" rather than "tonic," meaning the network now distinguishes between sequences that share the same words but in different orders. While a tonic representation might generate identical embeddings for "The dog chased the cat" and "The cat chased the dog," the phasic approach produces distinct values for each. This prevents the system from overfitting on keywords, ensuring that while rote calculation triggers a low-temperature state, the NCN can still apply high creativity to complex prompts like "Create a new mathematical conjecture about black holes" or "Unify Knot Theory and Number Theory" despite the mathematical vocabulary.

# Current Progress / Work / Optimization Branch
First of all, it trains. It trains smoothly. An 18M parameter model is currently being trained on TinyStories using the architecture found in the optimization branch. It is, so far, proving very stable and robust. It is highly likely the optimization branch will become the new main branch as we collect empirical evidence of the 18M model working as intended.

<img width="3600" height="2100" alt="convergence_analysis" src="https://github.com/user-attachments/assets/189ae6c9-ae90-4518-96b3-8a641b1bde29" />

This is the current experimental architecture (found on the experimental branch) undergoing its first training run (18M parameters on TinyStories). We are about 33% of the way through the training run. We look forward to the validation score. NCN regulation is holding steady between .0033 and .0034, implying the NCN has found an optimal position between 0 (not doing anything) and exploding gradients. Perplexity dropped to below 6 within the first 15% of the 1st epoch, implying high sample efficiency for this architecture.

The current model shows very high sample efficiency. Despite being a small model at 18M parameters, it 95% converged (Grammar, Syntax) on TinyStories by step 2540 with a Sample Efficiency Index of 2713. By step 6040, it had 99% converged (Intellectual) with a Sample Efficiency Index of 0.1955. If all goes well, this kind of architecture could greatly increase sample efficiency for training and lower compute costs.

<img width="4200" height="2400" alt="analysis_grammar_95" src="https://github.com/user-attachments/assets/2b513816-f7ac-4d3f-b565-b5a7d537fe17" />
<img width="4200" height="2400" alt="analysis_intellectual_99" src="https://github.com/user-attachments/assets/0bb01ba3-d484-4843-b92e-0b05ab966d93" />

## Future Work
While we're currently training the 18M model using the architecture, we must consider future work. Some future work ideas are laid out in the accompanying paper, such as testing if the NCN can modulate learning rate or a router for MoE or Mixture-of-Heads Attention, but there are more near term goals. After fully converged models are made (this 18M model will be a prime candidate), a generation / inference script will be written to produce text using the model. After this, a method will be devised to examine the temperature / precision, layer gains, and FF gating of the model as it undergoes inference, to see if the NCN is successfully modulating the outputs of the main LLM.




